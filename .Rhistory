# Instalación de paquetes necesarios para procesar datos:
install.packages(tm)
install.packages(wordcloud)
install.packages(quanteda)
install.packages(tidyr)
# Instalación de paquetes necesarios para procesar datos:
install.packages("tm")
install.packages("wordcloud")
install.packages("quanteda")
install.packages("tidyr")
library(ggplot2)
# Importaci?n de paquetes
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("syuzhet")
library("ggplot2")
library("readr")
library(rtweet)
library(ggplot2)
library(dplyr)
library(tidytext)
library("rjson")
app_details <- fromJSON(file = "api_key.json")
appname <- "hdt6-SC"
# create token named "twitter_token"
twitter_token <- create_token(
app = appname,
consumer_key = app_details$consumer_key,
consumer_secret = app_details$consumer_secret,
access_token = app_details$access_token,
access_secret = app_details$access_token_secret)
## search for 500 tweets using the #rstats hashtag
traficogt <- search_tweets(q = "@amilcarmontejo AND #traficogt",
n = 1000,
include_rts = FALSE)
# view the first 3 rows of the dataframe
head(traficogt$text, n = 100)
lapply(traficogt$text, write, "./tweets/test.txt", append=TRUE, ncolumns=100)
get_corpus <- function(dir) {
return (VCorpus(DirSource(dir, encoding = "UTF-8"), readerControl = list(language = "en")))
}
blogs <- get_corpus("./tweets")
#porciento <- 0.05
#set.seed(50)
#blogs[[1]]$content <- sample(blogs[[1]]$content, length(blogs[[1]]$content)*porciento)
# Funcion para cambiar a un espacio
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
# Eliminar URLs
# Extraido de: https://stackoverflow.com/questions/41109773/gsub-function-in-tm-package-to-remove-urls-does-not-remove-the-entire-string
#removeURL <- content_transformer(function(x) gsub("(f|ht)tp(s?)://\\S+", "", x, perl=T))
# Extraido de: https://stackoverflow.com/questions/30994194/quotes-and-hyphens-not-removed-by-tm-package-functions-while-cleaning-corpus
#removeSpecialChars <- content_transformer(function(x) gsub(""."","",x))
removeURL <- function(x) gsub("http[[:alnum:]]*", "", x)
removeURL2 <- function(x) gsub("www[[:alnum:]]*", "", x)
removeEmojis <- function(x) gsub("[^\x01-\x7F]", "", x)
### myCorpus <- tm_map(myCorpus, removeURL, lazy=TRUE)
data_cleaning <- function(corpus) {
#   - Normalizar Texto -> minuscula/mayuscula
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeURL))
corpus <- tm_map(corpus, content_transformer(removeURL2))
corpus <- tm_map(corpus, content_transformer(removeEmojis))
#   - Remover signos de puntuacion
corpus <- tm_map(corpus, removePunctuation)
#   - Remover numeros si no aportan nada.
corpus <- tm_map(corpus, removeNumbers)
#   - Remover articulos, preposiciones y conjunciones
corpus <- tm_map(corpus, removeWords, stopwords("english"))
#   - Remover  caracteres especiales
corpus <- tm_map(corpus, toSpace, "/")
corpus <- tm_map(corpus, toSpace, "@")
corpus <- tm_map(corpus, toSpace, "\\|")
corpus <- tm_map(corpus, toSpace, "#")
corpus <- tm_map(corpus, toSpace, "£")
#   - Remover emoticones
#   Non Ascii
#gsub("[^\x01-\x7F]", "", corpus)
#
#gsub(""."","",corpus)
#   - Remover espacios extra
corpus <- tm_map(corpus, stripWhitespace)
}
blogs <- data_cleaning(blogs)
term_doc_matrix <- function(corpus){
# Build a term-document matrix
tdm <- TermDocumentMatrix(corpus)
dtm_m <- as.matrix(tdm)
#Sort by descearing value of frequency
dtm_v <- sort(rowSums(dtm_m),decreasing=TRUE)
dtm_d <- data.frame(word = names(dtm_v),freq=dtm_v)
# Display the top 5 most frequent words
head(dtm_d, 5)
# palabras mas frecuents
barplot(dtm_d[1:5,]$freq, las = 2, names.arg = dtm_d[1:5,]$word,
col ="lightgreen", main ="Top 5 most frequent words",
ylab = "Word frequencies")
# nube de palabras
wordcloud(words = dtm_d$word, freq = dtm_d$freq, min.freq = 5,
max.words=100, random.order=FALSE, rot.per=0.40,
colors=brewer.pal(8, "Dark2"))
}
term_doc_matrix(blogs)
View(data_cleaning)
library(shiny); runApp('D:/UVG/4toAno/8voSem/DataScience/Lab9DS/lab9.R')
setwd("D:/UVG/4toAno/8voSem/DataScience/Lab9DS")
runApp('lab9.R')
clean_accidents <- read.csv("./accidentes/datosLimpios.csv")
colnames(clean_accidents)[colnames(clean_accidents) == 'a?.o_ocu'] <- 'anio_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'd?.a_ocu'] <- 'dia_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'd?.a_sem_ocu'] <- 'dia_sem_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'aÃ±o_ocu'] <- 'anio_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'dÃ­a_ocu'] <- 'dia_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'dÃ­a_sem_ocu'] <- 'dia_sem_ocu'
runApp('lab9.R')
clean_accidents <- read.csv("./accidentes/datosLimpios.csv")
colnames(clean_accidents)[colnames(clean_accidents) == 'aÃ±o_ocu'] <- 'anio_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'dÃ­a_ocu'] <- 'dia_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'dÃ­a_sem_ocu'] <- 'dia_sem_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'aÃ­o_ocu'] <- 'anio_ocu'
runApp('lab9.R')
clean_accidents <- read.csv("./accidentes/datosLimpios.csv")
colnames(clean_accidents)[colnames(clean_accidents) == 'aÃ­o_ocu'] <- 'anio_ocu'
clean_accidents <- read.csv("./accidentes/datosLimpios.csv")
colnames(clean_accidents)[colnames(clean_accidents) == 'aÃ.o_ocu'] <- 'anio_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'dÃ.a_ocu'] <- 'dia_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'dÃ.a_sem_ocu'] <- 'dia_sem_ocu'
runApp('lab9.R')
runApp('lab9.R')
library(shiny)
library(dplyr)
clean_accidents <- read.csv("./accidentes/datosLimpios.csv")
# renombrar columnas
colnames(clean_accidents)[colnames(clean_accidents) == 'a?.o_ocu'] <- 'anio_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'd?.a_ocu'] <- 'dia_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'd?.a_sem_ocu'] <- 'dia_sem_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'aÃ±o_ocu'] <- 'anio_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'dÃ­a_ocu'] <- 'dia_ocu'
colnames(clean_accidents)[colnames(clean_accidents) == 'dÃ­a_sem_ocu'] <- 'dia_sem_ocu'
#colnames(clean_accidents)[colnames(clean_accidents) == 'aÃ.o_ocu'] <- 'anio_ocu'
#(clean_accidents)[colnames(clean_accidents) == 'dÃ.a_ocu'] <- 'dia_ocu'
#colnames(clean_accidents)[colnames(clean_accidents) == 'dÃ.a_sem_ocu'] <- 'dia_sem_ocu'
# Graficas a estudiar
# Cantidad de accidentes por anio
yearly_accidents <- clean_accidents %>%
count(anio_ocu, sort=TRUE)
barplot(
yearly_accidents$n,
names.arg=yearly_accidents$anio_ocu,
main="Cantidad de accidentes por a?o",
xlab="A?o",
ylab="Accidentes",
col=palette(rainbow(10)),
cex.names=.7,
)
# Ocurrencias de accidentes por mes
monthly_accidents <- clean_accidents %>%
filter(clean_accidents["anio_ocu"] == 2015) %>%
count(mes_ocu, sort=TRUE)
barplot(
monthly_accidents$n,
names.arg=monthly_accidents$mes_ocu,
main="Cantidad de accidentes mensualmente",
xlab="Meses",
ylab="Accidentes",
col=palette(rainbow(10)),
cex.names=.7,
)
# Define UI for app that draws a histogram ----
ui <- fluidPage(
includeCSS("styles.css"),
titlePanel("Lab 9: Accidentes en Motocicletas en Guatemala"),
sidebarLayout(
position="right",
sidebarPanel("luis carlos esturban rodriguez"),
mainPanel(
textOutput("test_output"),
# Plot de accidentes agrupados por color y slider para elegir rango
# de aÃ±os.
fluidRow(
12, align="center",
plotOutput("acc_color", width="100%"),
),
fluidRow(
12, align="center",
sliderInput("year_range", "Rango de AÃ±os:",
min = 2015, max = 2018,
value = c(2015, 2018)
),
)
),
),
)
server = function(input, output, session) {
# state
count = reactiveValues(value=0)
# button callbacks
observeEvent(input$actionButton0, {
count$value = count$value + 1
})
output$text_output = renderText({
paste(
"clicked ",
count$value,
" times!"
)
})
# Grafica de accidentes agrupados por color, se accede a los valores de los
# sliders para definir los aÃ±os para filtrar los datos.
output$acc_color = renderPlot({
bike_colors <- clean_accidents %>%
filter(clean_accidents["anio_ocu"] >= input$year_range[1] & clean_accidents["anio_ocu"] <= input$year_range[2]) %>%
count(color_veh, sort=TRUE) %>%
top_n(10)
barplot(
bike_colors$n,
names.arg=bike_colors$color_veh,
main="Accidentes por Color y AÃ±os",
xlab="Color",
ylab="Cantidad",
col=palette(rainbow(10)),
cex.names=.7
)
})
}
# Create Shiny app ----
shinyApp(ui, server)
setwd("D:/UVG/4toAno/8voSem/DataScience/Lab9DS")
clean_accidents <- read.csv("./accidentes/datosLimpios.csv")
